{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31651af4-8007-4044-8184-dc5c64510ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "class SmartTickerExtractor:\n",
    "    def __init__(self):\n",
    "        self.patterns = [\n",
    "            (r'\\$([A-Z]{1,5})\\b', 1, 10.0),\n",
    "            (r'(?:NYSE|NASDAQ|LSE|TSE):\\s*([A-Z]{1,5})\\b', 1, 10.0),\n",
    "            (r'\\(([A-Z]{1,5})\\)', 1, 8.0),\n",
    "            (r'\\$([A-Z]{2,5}\\.[A-Z]{1,2})\\b', 1, 9.0),\n",
    "            (r'\\(([A-Z]{2,5}\\.[A-Z]{1,2})\\)', 1, 8.0),\n",
    "            (r'\\b([A-Z]{2,5}\\.[A-Z]{1,2})\\b', 0, 5.0),\n",
    "            (r'\\b([A-Z]{1,5})\\b', 0, 3.0),\n",
    "        ]\n",
    "        self.valid_tickers = {\n",
    "            \"AAPL\",\"MSFT\",\"NVDA\",\"AMD\",\"INTC\",\"QCOM\",\"CSCO\",\"ORCL\",\"IBM\",\"ADBE\",\"CRM\",\n",
    "            \"GOOGL\",\"META\",\"NFLX\",\"DIS\",\"VZ\",\"T\",\"TMUS\",\"PARA\",\"WBD\",\"TTWO\",\"EA\",\n",
    "            \"AMZN\",\"TSLA\",\"HD\",\"MCD\",\"NKE\",\"SBUX\",\"LOW\",\"BKNG\",\"TGT\",\"LVS\",\"RCL\",\n",
    "            \"PG\",\"KO\",\"PEP\",\"WMT\",\"COST\",\"PM\",\"MO\",\"CL\",\"KMB\",\"TAP\",\"GIS\",\n",
    "            \"XOM\",\"CVX\",\"COP\",\"SLB\",\"HAL\",\"EOG\",\"PSX\",\"VLO\",\"MPC\",\"OXY\",\"BKR\",\n",
    "            \"JPM\",\"BAC\",\"WFC\",\"C\",\"GS\",\"MS\",\"AXP\",\"SCHW\",\"BK\",\"BLK\",\"TFC\",\n",
    "            \"JNJ\",\"PFE\",\"MRK\",\"UNH\",\"LLY\",\"ABBV\",\"TMO\",\"DHR\",\"BMY\",\"AMGN\",\"CVS\",\n",
    "            \"CAT\",\"GE\",\"BA\",\"HON\",\"LMT\",\"NOC\",\"DE\",\"MMM\",\"RTX\",\"GD\",\"ETN\",\n",
    "            \"LIN\",\"SHW\",\"APD\",\"NEM\",\"DD\",\"FCX\",\"ECL\",\"VMC\",\"MLM\",\"CF\",\"ALB\",\n",
    "            \"NEE\",\"DUK\",\"SO\",\"D\",\"AEP\",\"EXC\",\"SRE\",\"XEL\",\"PEG\",\"ED\",\"WEC\",\n",
    "            \"PLD\",\"AMT\",\"EQIX\",\"CCI\",\"O\",\"PSA\",\"SPG\",\"WELL\",\"VICI\",\"DLR\",\"AVB\"\n",
    "        }\n",
    "        self.excluded_words = {\n",
    "            'CEO','CFO','COO','IPO','ETF','SEC','FDA','US','UK','USD',\n",
    "            'CNN','BBC','AI','IT','TV','APP','GDP','Q1','Q2','Q3','Q4',\n",
    "            'LLC','INC','LTD','CORP','CO','GROUP','PLC'\n",
    "        }\n",
    "\n",
    "    def extract_pattern_tickers(self, text):\n",
    "        text = text.upper() # test\n",
    "        ticker_scores = defaultdict(float)\n",
    "        for pattern, group_idx, score in self.patterns:\n",
    "            matches = re.finditer(pattern, text)\n",
    "            for match in matches:\n",
    "                ticker = match.group(group_idx).upper()\n",
    "                if ticker in self.valid_tickers:\n",
    "                    ticker_scores[ticker] += score\n",
    "        return ticker_scores\n",
    "\n",
    "    def is_valid_ticker(self, ticker):\n",
    "        if not ticker or ticker in self.excluded_words:\n",
    "            return False\n",
    "        return bool(re.match(r'^[A-Z]{1,5}$', ticker)) or bool(re.match(r'^[A-Z0-9]{2,6}\\.[A-Z]{1,2}$', ticker))\n",
    "\n",
    "    def extract_tickers(self, text):\n",
    "        scores = self.extract_pattern_tickers(text or \"\")\n",
    "        return list(scores.keys())\n",
    "\n",
    "sector_map = {\n",
    "    \"AAPL\":\"Technology\",\"MSFT\":\"Technology\",\"NVDA\":\"Technology\",\"AMD\":\"Technology\",\"INTC\":\"Technology\",\n",
    "    \"QCOM\":\"Technology\",\"CSCO\":\"Technology\",\"ORCL\":\"Technology\",\"IBM\":\"Technology\",\"ADBE\":\"Technology\",\"CRM\":\"Technology\",\n",
    "    \"GOOGL\":\"Communication Services\",\"META\":\"Communication Services\",\"NFLX\":\"Communication Services\",\n",
    "    \"DIS\":\"Communication Services\",\"VZ\":\"Communication Services\",\"T\":\"Communication Services\",\"TMUS\":\"Communication Services\",\n",
    "    \"PARA\":\"Communication Services\",\"WBD\":\"Communication Services\",\"TTWO\":\"Communication Services\",\"EA\":\"Communication Services\",\n",
    "    \"AMZN\":\"Consumer Discretionary\",\"TSLA\":\"Consumer Discretionary\",\"HD\":\"Consumer Discretionary\",\"MCD\":\"Consumer Discretionary\",\n",
    "    \"NKE\":\"Consumer Discretionary\",\"SBUX\":\"Consumer Discretionary\",\"LOW\":\"Consumer Discretionary\",\"BKNG\":\"Consumer Discretionary\",\n",
    "    \"TGT\":\"Consumer Discretionary\",\"LVS\":\"Consumer Discretionary\",\"RCL\":\"Consumer Discretionary\",\n",
    "    \"PG\":\"Consumer Staples\",\"KO\":\"Consumer Staples\",\"PEP\":\"Consumer Staples\",\"WMT\":\"Consumer Staples\",\"COST\":\"Consumer Staples\",\n",
    "    \"PM\":\"Consumer Staples\",\"MO\":\"Consumer Staples\",\"CL\":\"Consumer Staples\",\"KMB\":\"Consumer Staples\",\"TAP\":\"Consumer Staples\",\"GIS\":\"Consumer Staples\",\n",
    "    \"XOM\":\"Energy\",\"CVX\":\"Energy\",\"COP\":\"Energy\",\"SLB\":\"Energy\",\"HAL\":\"Energy\",\"EOG\":\"Energy\",\n",
    "    \"PSX\":\"Energy\",\"VLO\":\"Energy\",\"MPC\":\"Energy\",\"OXY\":\"Energy\",\"BKR\":\"Energy\",\n",
    "    \"JPM\":\"Financials\",\"BAC\":\"Financials\",\"WFC\":\"Financials\",\"C\":\"Financials\",\"GS\":\"Financials\",\"MS\":\"Financials\",\n",
    "    \"AXP\":\"Financials\",\"SCHW\":\"Financials\",\"BK\":\"Financials\",\"BLK\":\"Financials\",\"TFC\":\"Financials\",\n",
    "    \"JNJ\":\"Healthcare\",\"PFE\":\"Healthcare\",\"MRK\":\"Healthcare\",\"UNH\":\"Healthcare\",\"LLY\":\"Healthcare\",\"ABBV\":\"Healthcare\",\n",
    "    \"TMO\":\"Healthcare\",\"DHR\":\"Healthcare\",\"BMY\":\"Healthcare\",\"AMGN\":\"Healthcare\",\"CVS\":\"Healthcare\",\n",
    "    \"CAT\":\"Industrials\",\"GE\":\"Industrials\",\"BA\":\"Industrials\",\"HON\":\"Industrials\",\"LMT\":\"Industrials\",\"NOC\":\"Industrials\",\n",
    "    \"DE\":\"Industrials\",\"MMM\":\"Industrials\",\"RTX\":\"Industrials\",\"GD\":\"Industrials\",\"ETN\":\"Industrials\",\n",
    "    \"LIN\":\"Materials\",\"SHW\":\"Materials\",\"APD\":\"Materials\",\"NEM\":\"Materials\",\"DD\":\"Materials\",\"FCX\":\"Materials\",\n",
    "    \"ECL\":\"Materials\",\"VMC\":\"Materials\",\"MLM\":\"Materials\",\"CF\":\"Materials\",\"ALB\":\"Materials\",\n",
    "    \"NEE\":\"Utilities\",\"DUK\":\"Utilities\",\"SO\":\"Utilities\",\"D\":\"Utilities\",\"AEP\":\"Utilities\",\"EXC\":\"Utilities\",\n",
    "    \"SRE\":\"Utilities\",\"XEL\":\"Utilities\",\"PEG\":\"Utilities\",\"ED\":\"Utilities\",\"WEC\":\"Utilities\",\n",
    "    \"PLD\":\"Real Estate\",\"AMT\":\"Real Estate\",\"EQIX\":\"Real Estate\",\"CCI\":\"Real Estate\",\"O\":\"Real Estate\",\"PSA\":\"Real Estate\",\n",
    "    \"SPG\":\"Real Estate\",\"WELL\":\"Real Estate\",\"VICI\":\"Real Estate\",\"DLR\":\"Real Estate\",\"AVB\":\"Real Estate\",\n",
    "}\n",
    "\n",
    "class FFNN_Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        avg_embedded = embedded.mean(dim=1)\n",
    "        return self.fc(avg_embedded)\n",
    "\n",
    "def preprocess_text(text, vocab, max_len=30):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    ids = [vocab.get(t, 1) for t in tokens][:max_len]\n",
    "    ids += [0] * (max_len - len(ids))\n",
    "    return torch.tensor([ids], dtype=torch.long)\n",
    "\n",
    "def predict_sentiment(text, model, vocab, le):\n",
    "    x = preprocess_text(text, vocab)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits, dim=1).numpy()[0]\n",
    "        pred_idx = np.argmax(probs)\n",
    "        label = le.inverse_transform([pred_idx])[0]\n",
    "        confidence = float(probs[pred_idx])\n",
    "        score = (\n",
    "            -100 * confidence if \"negative\" in label.lower()\n",
    "            else 100 * confidence if \"positive\" in label.lower()\n",
    "            else 0\n",
    "        )\n",
    "    return label, score, confidence\n",
    "\n",
    "# =========================================================\n",
    "# MAIN PIPELINE\n",
    "# =========================================================\n",
    "def process_pipeline(input_csv, output_csv):\n",
    "    print(f\"Loading data from: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, dtype={\"published\": str})\n",
    "    print(f\"Loaded {len(df):,} rows\\n\")\n",
    "\n",
    "    print(\"Extracting tickers and sectors\")\n",
    "    extractor = SmartTickerExtractor()\n",
    "    tickers_list, sectors_list = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        title_text = str(row.get(\"title\", \"\"))\n",
    "        tickers = extractor.extract_tickers(title_text)\n",
    "        sectors = list({sector_map.get(t, None) for t in tickers if sector_map.get(t, None)}) if tickers else []\n",
    "        tickers_list.append(tickers)\n",
    "        sectors_list.append(sectors)\n",
    "\n",
    "    df[\"tickers\"] = tickers_list\n",
    "    df[\"sectors\"] = sectors_list\n",
    "\n",
    "    print(\"Loading model and running sentiment inference\")\n",
    "    vocab = joblib.load(r\"D:\\CSE 6242\\Project\\data\\vocab.pkl\")\n",
    "    le = joblib.load(r\"D:\\CSE 6242\\Project\\data\\label_encoder.pkl\")\n",
    "\n",
    "    model = FFNN_Embedding(\n",
    "        vocab_size=len(vocab),\n",
    "        embed_dim=100,\n",
    "        hidden_dim=256,\n",
    "        num_classes=len(le.classes_)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(r\"D:\\CSE 6242\\Project\\data\\sentiment_ffnn_model.pt\", map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "\n",
    "    tqdm.pandas(desc=\"Running Sentiment Model\")\n",
    "    results = df[\"title\"].progress_apply(lambda t: predict_sentiment(str(t), model, vocab, le))\n",
    "\n",
    "    df[\"sentiment_label\"] = results.apply(lambda x: x[0])\n",
    "    df[\"sentiment_score\"] = results.apply(lambda x: x[1])\n",
    "    df[\"confidence\"] = results.apply(lambda x: x[2])\n",
    "\n",
    "    columns_to_keep = [\n",
    "        \"published\", \"title\", \"tickers\", \"sectors\",\n",
    "        \"sentiment_label\", \"sentiment_score\", \"confidence\"\n",
    "    ]\n",
    "    df[columns_to_keep].to_csv(output_csv, index=False)\n",
    "    print(f\"Output saved to: {output_csv}\")\n",
    "    print(df[columns_to_keep].head(10))\n",
    "\n",
    "process_pipeline(\n",
    "    input_csv=r\"D:\\CSE 6242\\Project\\data\\merged_sentiment_news.csv\",\n",
    "    output_csv=r\"D:\\CSE 6242\\Project\\data\\final_merged_with_sentiment.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2123c0-2437-4612-b3f9-7c1e2f05d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import timedelta\n",
    "\n",
    "input_path = r\"D:\\CSE 6242\\Project\\data\\final_merged_with_sentiment.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "\n",
    "def safe_parse_list(x):\n",
    "    try:\n",
    "        if isinstance(x, str) and x.startswith(\"[\"):\n",
    "            return ast.literal_eval(x)\n",
    "        elif isinstance(x, list):\n",
    "            return x\n",
    "        elif pd.isna(x):\n",
    "            return []\n",
    "        else:\n",
    "            return [str(x)]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "df[\"tickers\"] = df[\"tickers\"].apply(safe_parse_list)\n",
    "df[\"sectors\"] = df[\"sectors\"].apply(safe_parse_list)\n",
    "\n",
    "df[\"published\"] = pd.to_datetime(df[\"published\"], errors=\"coerce\")\n",
    "max_date = df[\"published\"].max().normalize()\n",
    "cutoff = max_date - timedelta(days=90)\n",
    "df = df[df[\"published\"] >= cutoff].copy()\n",
    "df[\"date\"] = df[\"published\"].dt.normalize()\n",
    "\n",
    "print(f\"Filtered to {cutoff.date()} to {max_date.date()} ({len(df):,} rows remain)\")\n",
    "\n",
    "df_exp_tickers = df.explode(\"tickers\")\n",
    "df_exp_sectors = df.explode(\"sectors\")\n",
    "\n",
    "ticker_daily = (\n",
    "    df_exp_tickers.dropna(subset=[\"tickers\"])\n",
    "    .groupby([\"date\", \"tickers\"])[\"sentiment_score\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"tickers\": \"ticker\", \"sentiment_score\": \"avg_sentiment_score\"})\n",
    ")\n",
    "\n",
    "sector_daily = (\n",
    "    df_exp_sectors.dropna(subset=[\"sectors\"])\n",
    "    .groupby([\"date\", \"sectors\"])[\"sentiment_score\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sectors\": \"sector\", \"sentiment_score\": \"avg_sentiment_score\"})\n",
    ")\n",
    "\n",
    "def add_rolling(df, group_col):\n",
    "    df = df.sort_values([\"date\"])\n",
    "    df[\"rolling_90d_sentiment\"] = (\n",
    "        df.groupby(group_col)[\"avg_sentiment_score\"]\n",
    "        .transform(lambda s: s.rolling(window=90, min_periods=1).mean())\n",
    "    )\n",
    "    return df\n",
    "\n",
    "ticker_stats = add_rolling(ticker_daily, \"ticker\")\n",
    "sector_stats = add_rolling(sector_daily, \"sector\")\n",
    "\n",
    "# === 7. Save outputs ===\n",
    "ticker_out = r\"D:\\CSE 6242\\Project\\data\\merged_ticker_sentiment_stats_90d.csv\"\n",
    "sector_out = r\"D:\\CSE 6242\\Project\\data\\merged_sector_sentiment_stats_90d.csv\"\n",
    "\n",
    "ticker_stats.to_csv(ticker_out, index=False)\n",
    "sector_stats.to_csv(sector_out, index=False)\n",
    "\n",
    "print(f\"Saved ticker stats to {ticker_out}\")\n",
    "print(f\"Saved sector stats to {sector_out}\")\n",
    "\n",
    "print(\"Ticker sentiment sample:\")\n",
    "print(ticker_stats.head(10))\n",
    "\n",
    "print(\"Sector sentiment sample:\")\n",
    "print(sector_stats.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
